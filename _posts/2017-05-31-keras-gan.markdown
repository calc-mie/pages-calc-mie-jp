---
title: "KerasでGAN"
author: "naca_cyan13"
---

前回の記事 - [Mnistチュートリアルをやってみた](https://www.calc.mie.jp/posts/2017-04-30-mnist-tutorial-tf.html)

**Keras**は簡単にニューラルネットワークを扱うことができるライブラリです。それを使ってみて学ぼう、というのがこの記事の目的です。Kerasの各機能をまとめ、GANという機械学習モデルを実装しました。

今回も完全に手探りなので、間違いはDisqusで指摘しまくってください。

# Kerasとは

Keras Documentation より

> Kerasは，Pythonで書かれた，TensorFlowまたはTheano上で実行可能な高水準のニュー ラルネットワークライブラリです． Kerasは，迅速な実験を可能にすることに重点を置いて開発されました． 可能な限り遅れなくアイデアから結果に進められることは，良い研究をする上で重要です．

では具体的にどのように使うのかを見て行きましょう。

## Sequential

Kerasを使って学習モデルを構築する上で、コアとなるものが`Sequential`オブジェクトです。
`Sequential`はモデルのレイヤーを積み重ねたものです。

例えば入力層784次元、中間層1024次元、出力層10次元のニューラルネットワークの構築                                               は以下のコードで実装できます。

```python
from keras.models import Sequential
from keras.layers import Dense, Activation

model = Sequntial()
model.add(Dense(1024, input_dim=784))
model.add(Activation('sigmoid'))
model.add(Dense(10))
model.add(Activation('softmax'))
```

次に、各レイヤーのオブジェクトとしてどんなものが用意されているのかまとめます。

### Dense, Activate

上の例で登場した`Dense`は全結合ニューラルネットワークレイヤーです。
`Activation`は活性化レイヤーで、`RuLU`や`sigmoid`、`tanh`など多数用意されていま                                               す。

### Convolution, UpSampling

`Convolution`は畳み込みニューラルネットワークレイヤー(CNN)です。CNNについては後                                               述します。`UpSampling`とはベクトルの次元を増やすもので、画像を引き伸ばすようなイ                                               メージのものです。

### その他
その他にも`MaxPooling`や`LocallyConnected`などのレイヤーオブジェクトが用意されて                                               います。
しかし、今回のテーマには使わなかったので今後使う機会があったらまとめようと思いま                                               す。

# CNNとは

CNN(Convolutional Neural Network)とは、ニューラルネットワークに畳み込みフィルタ                                               の概念を持ち込んだものです。画像におけるCNNを、数式を使って説明します。

$\mathrm{x}$ を画像、$M$、$N$ を画像のサイズ、$\omega$を畳み込みフィルタ、
$m$、$n$ を畳み込みフィルタのサイズ、$\mathrm{b}$をバイアス、
$k$ をフィルタのインデックスとしたとき、出力$\mathrm{a}^{k}$は

$$ a_{ij}^{k} =\sum_{s=0}^{m-1} \sum_{t=0}^{n-1} \omega_{st}^{k} x_{i + s, j + t} + b^{k} $$

となります。ここで、CNNレイヤーを通ったあとのテンソルのランクを考えます。もとの画像が行列、つまり2階テンソル。これがフィルタの数だけ積み上がるので、3階のテンソルになります。

次に、CNNにおける学習を見てみましょう。学習すべきパラメータは$\omega$と$b$です。これをバックプロパゲーションで学習させます。損失関数を$E$とすると、修正量$\Delta \omega_{st}^k$、$\Delta b^k$はそれぞれ

$$ \Delta \omega_{st}^k = - \eta_{\omega} \sum_{i=0}^{M-m} \sum_{j=0}^{N-n} \frac{\partial E}{ \partial a_{ij}^k} \frac{\partial a_{ij}^k}{\partial \omega_{st}^{k}} $$
$$ \Delta b^k = - \eta_{b} \sum_{i=0}^{M-m} \sum_{j = 0}^{N - n} \frac{\partial E}{\partial a_{ij}^k} \frac{\partial a_{ij}^k}{\partial b^k} $$

となります。ただし$\eta_{\omega}$、$\eta_{b}$は学習係数です。もっと多層になる場合も、連鎖律を使って分解すれば求めることができます。

---

# 改めて今回やったこと 

GANという学習モデルを使って、りんごの画像を読み取らせ、それに似たような画像を出力させてみました。

## GANとは

GAN(Generative Adversarial Network)とは、生成モデルGeneratorと、識別モデルDiscriminatorを使って、訓練データと似たようなものを生成するための学習モデルです。

学習について説明します。まずに乱数のベクトルを入力します。それを元に、Generatorが画像をネットワークを使って生成します。その生成された画像と訓練データを交互にDiscriminatorに入力します。このとき、Discrimatorはその画像が訓練データであるなら1を、そうでない（偽物）なら0を出力させるようにします。その教師信号をGeneratorにも伝播させます。

この学習により、Discriminatorはより正確に生成された画像と訓練データを識別できるようになり、Generatorはより正確に訓練データとそっくりな画像を生成する事ができるようになります。


## 今回使った学習モデル

Kerasには学習モデルを画像として出力する機能があります。以下が今回使った学習モデルの画像です。実装は[ここ](https://elix-tech.github.io/ja/2017/02/06/gan.html )のコードをかなり参考にさせていただきました。

右:Generator、左:Discriminator

<img src="../images/keras-generator.png" width="40%"><img src="../images/keras-discriminator.png" width="35%" >


## 訓練データ

googleさんで適当に「りんご　画像」と検索して出てきたものをダウンロードしました。

 [りんご 画像](https://www.google.co.jp/search?q=%E3%82%8A%E3%82%93%E3%81%94+%E7%94%BB%E5%83%8F&oq=%E3%82%8A%E3%82%93%E3%81%94+%E7%94%BB%E5%83%8F&aqs=chrome..69i57j0l5.3699j0j7&sourceid=chrome&ie=UTF-8)

## 結果

batch 0

![](../images/keras-gan0.png)

batch 2500

![](../images/keras-gan2500.png)

batch 5000

![](../images/keras-gan5000.png)

# まとめ

ハイパーパラメータの調整方法を知らないのと、RGBの3色の色ベクトルと畳み込みでできたチャネルをごっちゃにしてCNNに流したりしているので、色がバラバラになっている部分があります。

また、こんなにもニューラルネットワークがメモリを食うものとは思わなかったので、最初は256x256(x3)の画像を読ませようとしてpythonに怒られたりと、そのあたりで学ぶことが多かったです。近いうちにRGB画像対応のGANのもっとよい実装をやってみたいと思います。

GANの実装を通して、Kerasやニューラルネットワークについて知るという目的は概ね達成されたので満足です。

# 今後やりたいこと

次は画像から離れ、RNN(Recurrent Neural Network)などをつかって、チャットボットなどを作れたらいいなと思っています。

# 参考文献

 - [はじめてのGAN](https://elix-tech.github.io/ja/2017/02/06/gan.html)
 - [数式で書き下す Convolutional Neural Networks (CNN)  - Yusuke Sugomori's Blog](http://blog.yusugomori.com/post/129688163130/%E6%95%B0%E5%BC%8F%E3%81%A7%E6%9B%B8%E3%81%8D%E4%B8%8B%E3%81%99-convolutional-neural-networks-cnn)
 - [Keras](https://keras.io/ja/)

